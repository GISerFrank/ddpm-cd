# Change detection head (version 2 - Flexible) - FINAL CORRECT VERSION
# ğŸ”¥ å…³é”®ä¿®æ­£ï¼šfeats_A[0] åªåŒ…å«é…ç½®çš„feat_scalesï¼Œä¸æ˜¯å®Œæ•´çš„0-14ç´¢å¼•ï¼

import torch
import torch.nn as nn
import torch.nn.functional as F

try:
    from model.cd_modules.se import ChannelSpatialSELayer
    USE_ORIGINAL_SE = True
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ°ChannelSpatialSELayerï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    USE_ORIGINAL_SE = False


def get_in_channels(feat_scales, inner_channel, channel_multiplier):
    '''Get the number of input layers to the change detection head.'''
    in_channels = 0
    for scale in feat_scales:
        if scale < 3:
            in_channels += inner_channel*channel_multiplier[0]
        elif scale < 6:
            in_channels += inner_channel*channel_multiplier[1]
        elif scale < 9:
            in_channels += inner_channel*channel_multiplier[2]
        elif scale < 12:
            in_channels += inner_channel*channel_multiplier[3]
        elif scale < 15:
            in_channels += inner_channel*channel_multiplier[4]
        else:
            print('Unbounded number for feat_scales. 0<=feat_scales<=14') 
    return in_channels


def get_resolution_from_scale(scale):
    """æ ¹æ®scaleç´¢å¼•è·å–å¯¹åº”çš„åˆ†è¾¨ç‡"""
    if scale < 3:    return 256
    elif scale < 6:  return 128
    elif scale < 9:  return 64
    elif scale < 12: return 32
    elif scale < 15: return 16
    else: raise ValueError(f"Invalid scale: {scale}")


class AttentionBlock(nn.Module):
    def __init__(self, dim, dim_out):
        super().__init__()
        if USE_ORIGINAL_SE:
            self.block = nn.Sequential(
                nn.Conv2d(dim, dim_out, 3, padding=1),
                nn.ReLU(),
                ChannelSpatialSELayer(num_channels=dim_out, reduction_ratio=2)
            )
        else:
            self.block = nn.Sequential(
                nn.Conv2d(dim, dim_out, 3, padding=1),
                nn.ReLU()
            )

    def forward(self, x):
        return self.block(x)


class Block(nn.Module):
    def __init__(self, dim, dim_out, time_steps):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(dim*len(time_steps), dim, 1) 
            if len(time_steps)>1
            else nn.Identity(),
            nn.ReLU()
            if len(time_steps)>1
            else nn.Identity(),
            nn.Conv2d(dim, dim_out, 3, padding=1),
            nn.ReLU()
        )

    def forward(self, x):
        return self.block(x)


class cd_head_v2_flexible(nn.Module):
    '''
    Change detection head (version 2 - Flexible) FINAL CORRECT VERSION
    
    ğŸ”¥ å…³é”®ç†è§£ï¼š
    - feats_A[0] çš„é•¿åº¦ = len(feat_scales)ï¼Œä¸æ˜¯15ï¼
    - feats_A[0][i] å¯¹åº” feat_scales[i] çš„ç‰¹å¾
    - æ‰€ä»¥ç›´æ¥ç”¨ lvl_idx ç´¢å¼•å³å¯ï¼šfeats_A[0][lvl_idx] âœ“
    '''

    def __init__(self, feat_scales, out_channels=2, inner_channel=None, 
                 channel_multiplier=None, img_size=256, time_steps=None):
        super(cd_head_v2_flexible, self).__init__()

        feat_scales.sort(reverse=True)
        self.feat_scales = feat_scales
        self.in_channels = get_in_channels(feat_scales, inner_channel, channel_multiplier)
        self.img_size = img_size
        self.time_steps = time_steps if time_steps is not None else [0]

        # è®¡ç®—è§£ç å™¨è¾“å‡ºåˆ†è¾¨ç‡
        self.min_scale = min(feat_scales)
        self.decoder_output_res = get_resolution_from_scale(self.min_scale)
        
        print(f"\nğŸ¯ Flexible CD Head - FINAL CORRECT é…ç½®:")
        print(f"   feat_scales: {self.feat_scales}")
        print(f"   ä½¿ç”¨åŸç‰ˆSE: {USE_ORIGINAL_SE}")
        print(f"   è§£ç å™¨è¾“å‡ºåˆ†è¾¨ç‡: {self.decoder_output_res}Ã—{self.decoder_output_res}")
        print(f"   ç›®æ ‡è¾“å‡ºåˆ†è¾¨ç‡: {img_size}Ã—{img_size}")

        # Decoder
        self.decoder = nn.ModuleList()
        current_decoder_output_channels = 0
        
        for i in range(len(self.feat_scales)):
            dim = get_in_channels([self.feat_scales[i]], inner_channel, channel_multiplier)
            
            self.decoder.append(
                Block(dim=dim, dim_out=dim, time_steps=self.time_steps)
            )
            current_block_output_channels = dim

            if i != len(self.feat_scales)-1:
                dim_out = get_in_channels([self.feat_scales[i+1]], inner_channel, channel_multiplier)
                self.decoder.append(
                    AttentionBlock(dim=current_block_output_channels, dim_out=dim_out)
                )
                current_decoder_output_channels = dim_out
            else:
                current_decoder_output_channels = current_block_output_channels

        # ä¸Šé‡‡æ ·å±‚
        self.upsample_layers = nn.ModuleList()
        current_res = self.decoder_output_res
        
        upsample_factor = img_size // current_res
        num_upsample = 0
        temp_factor = upsample_factor
        while temp_factor > 1:
            temp_factor //= 2
            num_upsample += 1
        
        if num_upsample > 0:
            print(f"   æ·»åŠ {num_upsample}ä¸ªä¸Šé‡‡æ ·å±‚ ({current_res}Ã—{current_res} -> {img_size}Ã—{img_size})")
            
            in_channels_upsample = current_decoder_output_channels
            for i in range(num_upsample):
                out_channels_upsample = max(in_channels_upsample // 2, 64)
                
                self.upsample_layers.append(nn.Sequential(
                    nn.Conv2d(in_channels_upsample, out_channels_upsample, 3, padding=1),
                    nn.ReLU(),
                    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
                    nn.Conv2d(out_channels_upsample, out_channels_upsample, 3, padding=1),
                    nn.ReLU()
                ))
                in_channels_upsample = out_channels_upsample
            
            final_channels = in_channels_upsample
        else:
            print(f"   æ— éœ€é¢å¤–ä¸Šé‡‡æ ·")
            final_channels = current_decoder_output_channels

        print()  # ç©ºè¡Œ

        # åˆ†ç±»å¤´
        clfr_emb_dim = 64
        self.clfr_stg1 = nn.Conv2d(final_channels, clfr_emb_dim, kernel_size=3, padding=1)
        self.clfr_stg2 = nn.Conv2d(clfr_emb_dim, out_channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU()

    def forward(self, feats_A, feats_B):
        # Decoder
        lvl_idx = 0
        x = None

        for layer_idx, layer in enumerate(self.decoder):
            if isinstance(layer, Block):
                # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ä¿®æ­£ï¼šç›´æ¥ç”¨lvl_idxç´¢å¼•ï¼
                # feats_A[0] åªæœ‰ len(feat_scales) ä¸ªå…ƒç´ 
                # feats_A[0][0] å¯¹åº” feat_scales[0] çš„ç‰¹å¾
                # feats_A[0][1] å¯¹åº” feat_scales[1] çš„ç‰¹å¾
                # ...
                current_scale_feat_A = feats_A[0][lvl_idx]  # âœ“ æ­£ç¡®ï¼
                current_scale_feat_B = feats_B[0][lvl_idx]

                # å¤šæ—¶é—´æ­¥æ‹¼æ¥
                if len(self.time_steps) > 1:
                    list_to_cat_A = [feats_A[t_idx][lvl_idx] 
                                     for t_idx in range(len(self.time_steps))]
                    list_to_cat_B = [feats_B[t_idx][lvl_idx] 
                                     for t_idx in range(len(self.time_steps))]
                    f_A_cat = torch.cat(list_to_cat_A, dim=1)
                    f_B_cat = torch.cat(list_to_cat_B, dim=1)
                else:
                    f_A_cat = current_scale_feat_A
                    f_B_cat = current_scale_feat_B
    
                processed_f_A = layer(f_A_cat)
                processed_f_B = layer(f_B_cat)
                diff = torch.abs(processed_f_A - processed_f_B)
                
                if x is not None:
                    diff = diff + x
                
                lvl_idx += 1
                
            else:  # AttentionBlock
                diff = layer(diff)
                if layer_idx < len(self.decoder) - 1:
                    x = F.interpolate(diff, scale_factor=2, mode="bilinear", align_corners=False)
                else:
                    x = diff

        # åº”ç”¨ä¸Šé‡‡æ ·å±‚
        for upsample_layer in self.upsample_layers:
            x = upsample_layer(x)

        # åˆ†ç±»
        cm = self.clfr_stg2(self.relu(self.clfr_stg1(x)))
        return cm
