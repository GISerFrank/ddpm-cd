"""
å¤šå°ºåº¦ç‰©ç†ç‰¹å¾é‡‘å­—å¡”ç¼–ç å™¨ - DDPM-Awareç‰ˆæœ¬

æ”¹è¿›ï¼š
1. ä¸å†æ˜¯å•å°ºåº¦ç¼–ç +æ’å€¼ï¼Œè€Œæ˜¯æ„å»ºç‰©ç†ç‰¹å¾é‡‘å­—å¡”
2. ä¸ºæ¯ä¸ªDDPMç‰¹å¾å°ºåº¦ç”Ÿæˆå¯¹åº”çš„ç‰©ç†ç‰¹å¾
3. æ·±å±‚å…³æ³¨å±€éƒ¨ç»†èŠ‚ï¼Œæµ…å±‚å…³æ³¨å…¨å±€å½¢æ€
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class PhysicalFeaturePyramid(nn.Module):
    """
    ç‰©ç†ç‰¹å¾é‡‘å­—å¡”ç¼–ç å™¨ - ç±»ä¼¼DDPMçš„U-Netç»“æ„
    
    æ ¹æ®feat_scalesåŠ¨æ€ç”Ÿæˆå¯¹åº”å°ºåº¦çš„ç‰©ç†ç‰¹å¾
    ä»configè‡ªåŠ¨è¯»å–: feat_scales, inner_channel, channel_multiplier
    """
    
    def __init__(self, opt, num_physical_layers=2, num_groups=8):
        """
        Args:
            opt: é…ç½®å­—å…¸ï¼ŒåŒ…å« model_cd å’Œ model.unet é…ç½®
            num_physical_layers: ç‰©ç†æ•°æ®å±‚æ•° (é»˜è®¤2: DEM+Slope)
            num_groups: GroupNormçš„ç»„æ•° (é»˜è®¤8)
        """
        super().__init__()
        
        # ä»configè¯»å–å‚æ•°
        feat_scales = opt['model_cd']['feat_scales']
        inner_channel = opt['model']['unet']['inner_channel']
        channel_multiplier = opt['model']['unet']['channel_multiplier']
        
        self.num_physical_layers = num_physical_layers
        self.feat_scales = sorted(feat_scales, reverse=True)  # ä»æ·±åˆ°æµ…
        self.num_groups = num_groups
        
        # è®¡ç®—æ¯ä¸ªå°ºåº¦çš„é€šé“æ•°ï¼ˆä¸DDPMç‰¹å¾å¯¹é½ï¼‰
        self.scale_channels = {}
        for scale in feat_scales:
            channels = self._get_channels_for_scale(scale, inner_channel, channel_multiplier)
            self.scale_channels[scale] = channels
        
        # åˆå§‹å·ç§¯ï¼šç‰©ç†æ•°æ® â†’ åŸºç¡€ç‰¹å¾
        self.initial_conv = nn.Sequential(
            nn.Conv2d(num_physical_layers, 32, 3, padding=1),
            nn.GroupNorm(num_groups, 32),
            nn.SiLU()
        )
        
        # ç¼–ç å™¨ï¼šé€æ­¥ä¸‹é‡‡æ ·ï¼Œæå–å±‚æ¬¡åŒ–ç‰¹å¾
        self.encoders = nn.ModuleDict()
        current_channels = 32
        
        # ä»æœ€æµ…å±‚(256x256)åˆ°æœ€æ·±å±‚(16x16)æ„å»ºç¼–ç å™¨
        # å‡è®¾å°ºåº¦å¯¹åº”å…³ç³»ï¼šscale 0â†’256, 3â†’128, 6â†’64, 9â†’32, 12â†’16
        scale_to_resolution = {
            0: 256, 1: 256, 2: 256,
            3: 128, 4: 128, 5: 128,
            6: 64, 7: 64, 8: 64,
            9: 32, 10: 32, 11: 32,
            12: 16, 13: 16, 14: 16
        }
        
        # è·å–éœ€è¦çš„åˆ†è¾¨ç‡
        resolutions = sorted(set([scale_to_resolution[s] for s in feat_scales]), reverse=True)
        
        for i, res in enumerate(resolutions):
            if i > 0:  # éœ€è¦ä¸‹é‡‡æ ·
                # ä¸‹é‡‡æ ·å—
                next_channels = min(current_channels * 2, 512)
                self.encoders[f'downsample_{res}'] = nn.Sequential(
                    nn.Conv2d(current_channels, next_channels, 3, stride=2, padding=1),
                    nn.GroupNorm(num_groups, next_channels),
                    nn.SiLU(),
                    nn.Conv2d(next_channels, next_channels, 3, padding=1),
                    nn.GroupNorm(num_groups, next_channels),
                    nn.SiLU()
                )
                current_channels = next_channels
        
        # ä¸ºæ¯ä¸ªfeat_scaleåˆ›å»ºè¾“å‡ºæŠ•å½±
        self.scale_projections = nn.ModuleDict()
        for scale in feat_scales:
            res = scale_to_resolution[scale]
            target_channels = self.scale_channels[scale]
            
            # æ‰¾åˆ°å¯¹åº”åˆ†è¾¨ç‡çš„ç¼–ç å™¨è¾“å‡ºé€šé“æ•°
            encoder_channels = current_channels if res == min(resolutions) else 32 * (256 // res)
            encoder_channels = min(encoder_channels, 512)
            
            self.scale_projections[str(scale)] = nn.Sequential(
                nn.Conv2d(encoder_channels, target_channels, 1),
                nn.GroupNorm(num_groups, target_channels),
                nn.SiLU()
            )
    
    def _get_channels_for_scale(self, scale, inner_channel, channel_multiplier):
        """è·å–ç‰¹å®šå°ºåº¦çš„é€šé“æ•°ï¼ˆä¸DDPMç‰¹å¾å¯¹é½ï¼‰"""
        if scale < 3:
            return inner_channel * channel_multiplier[0]
        elif scale < 6:
            return inner_channel * channel_multiplier[1]
        elif scale < 9:
            return inner_channel * channel_multiplier[2]
        elif scale < 12:
            return inner_channel * channel_multiplier[3]
        elif scale < 15:
            return inner_channel * channel_multiplier[4]
        else:
            raise ValueError(f"Unsupported scale: {scale}")
    
    def forward(self, physical_data):
        """
        Args:
            physical_data: [B, num_layers, 256, 256] - åŸå§‹ç‰©ç†æ•°æ®
        
        Returns:
            pyramid_features: Dict[scale -> Tensor]
                ä¾‹å¦‚: {12: [B,512,16,16], 6: [B,256,64,64], 0: [B,64,256,256]}
        """
        # åˆå§‹ç¼–ç 
        x = self.initial_conv(physical_data)  # [B, 32, 256, 256]
        
        # å­˜å‚¨ä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾
        resolution_features = {256: x}
        
        # é€æ­¥ä¸‹é‡‡æ ·
        scale_to_resolution = {
            0: 256, 1: 256, 2: 256,
            3: 128, 4: 128, 5: 128,
            6: 64, 7: 64, 8: 64,
            9: 32, 10: 32, 11: 32,
            12: 16, 13: 16, 14: 16
        }
        
        resolutions = sorted(set([scale_to_resolution[s] for s in self.feat_scales]), reverse=True)
        current_x = x
        
        for res in resolutions:
            if res < 256:  # éœ€è¦ä¸‹é‡‡æ ·
                current_x = self.encoders[f'downsample_{res}'](current_x)
            resolution_features[res] = current_x
        
        # ä¸ºæ¯ä¸ªscaleç”Ÿæˆç‰¹å¾
        pyramid_features = {}
        for scale in self.feat_scales:
            res = scale_to_resolution[scale]
            feat = resolution_features[res]
            
            # æŠ•å½±åˆ°ç›®æ ‡é€šé“æ•°
            projected = self.scale_projections[str(scale)](feat)
            pyramid_features[scale] = projected
        
        return pyramid_features


# ========== å‘åå…¼å®¹çš„åŒ…è£…å™¨ ==========
class PhysicalFeatureEncoder(nn.Module):
    """
    å‘åå…¼å®¹çš„ç‰©ç†ç¼–ç å™¨ï¼ˆå•å°ºåº¦ç‰ˆæœ¬ï¼‰
    """
    def __init__(self, num_physical_layers=2, hidden_dims=[32, 64, 128], 
                 output_dim=64, num_groups=8):
        super().__init__()
        
        self.initial_conv = nn.Sequential(
            nn.Conv2d(num_physical_layers, hidden_dims[0], 3, padding=1),
            nn.GroupNorm(num_groups, hidden_dims[0]),
            nn.SiLU()
        )
        
        self.encoder_blocks = nn.ModuleList()
        layer_dims = list(zip(hidden_dims[:-1], hidden_dims[1:]))
        
        for in_ch, out_ch in layer_dims:
            block = nn.Sequential(
                nn.Conv2d(in_ch, out_ch, 3, padding=1),
                nn.GroupNorm(num_groups, out_ch),
                nn.SiLU(),
                nn.Conv2d(out_ch, out_ch, 3, padding=1),
                nn.GroupNorm(num_groups, out_ch),
                nn.SiLU()
            )
            self.encoder_blocks.append(block)
        
        self.output_proj = nn.Sequential(
            nn.Conv2d(hidden_dims[-1], output_dim, 1),
            nn.GroupNorm(num_groups, output_dim),
            nn.SiLU()
        )
        
    def forward(self, physical_data):
        x = self.initial_conv(physical_data)
        for block in self.encoder_blocks:
            x = block(x)
        encoded = self.output_proj(x)
        return encoded


# ========== æµ‹è¯•ä»£ç  ==========
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯• PhysicalFeaturePyramid")
    
    # æ¨¡æ‹Ÿconfig
    test_opt = {
        'model_cd': {
            'feat_scales': [14, 11, 8, 5]
        },
        'model': {
            'unet': {
                'inner_channel': 128,
                'channel_multiplier': [1, 2, 4, 8, 8]
            }
        }
    }
    
    # åˆ›å»ºé‡‘å­—å¡”ç¼–ç å™¨
    pyramid_encoder = PhysicalFeaturePyramid(
        opt=test_opt,
        num_physical_layers=2,
        num_groups=8
    )
    
    # æµ‹è¯•è¾“å…¥
    batch_size = 2
    physical_data = torch.randn(batch_size, 2, 256, 256)
    
    # å‰å‘ä¼ æ’­
    pyramid_features = pyramid_encoder(physical_data)
    
    print(f"âœ… è¾“å…¥ç‰©ç†æ•°æ®: {physical_data.shape}")
    print(f"\nç”Ÿæˆçš„å¤šå°ºåº¦ç‰©ç†ç‰¹å¾é‡‘å­—å¡”:")
    for scale in sorted(pyramid_features.keys(), reverse=True):
        feat = pyramid_features[scale]
        print(f"  Scale {scale:2d}: {feat.shape}")
    
    # éªŒè¯é€šé“æ•°
    print(f"\nâœ… é€šé“æ•°ä¸DDPMç‰¹å¾å¯¹é½:")
    # inner_channel=128, channel_multiplier=[1,2,4,8,8]
    expected_channels = {
        14: 1024,  # 128*8
        11: 1024,  # 128*8
        8: 512,    # 128*4
        5: 256     # 128*2
    }
    for scale, expected in expected_channels.items():
        actual = pyramid_features[scale].shape[1]
        status = "âœ…" if actual == expected else "âŒ"
        print(f"  Scale {scale}: {actual} channels (expected {expected}) {status}")
    
    # æ£€æŸ¥æ¨¡å—
    has_groupnorm = any('GroupNorm' in str(type(m)) for m in pyramid_encoder.modules())
    has_silu = any('SiLU' in str(type(m)) for m in pyramid_encoder.modules())
    has_batchnorm = any('BatchNorm' in str(type(m)) for m in pyramid_encoder.modules())
    
    print(f"\næ¨¡å—æ£€æŸ¥:")
    print(f"  - GroupNorm: {'âœ…' if has_groupnorm else 'âŒ'}")
    print(f"  - SiLU: {'âœ…' if has_silu else 'âŒ'}")
    print(f"  - BatchNorm: {'âŒ' if not has_batchnorm else 'âš ï¸'}")
    
    print(f"\nğŸ‰ æµ‹è¯•é€šè¿‡ï¼")
