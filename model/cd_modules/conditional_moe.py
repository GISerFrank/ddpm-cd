"""
æ¡ä»¶åŒ–ä¸“å®¶å†³ç­–æ¨¡å— (Conditional Expert Decision with MoE)
ç¬¬äº”é˜¶æ®µï¼šæ ¹æ®æ»‘å¡è¯±å› ç±»åˆ«ï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä¸“å®¶è¿›è¡Œæœ€ç»ˆåˆ†æ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math


class ExpertNetwork(nn.Module):
    """
    å•ä¸ªä¸“å®¶ç½‘ç»œ
    æ¯ä¸ªä¸“å®¶ä¸“é—¨å¤„ç†ç‰¹å®šç±»å‹çš„æ»‘å¡è¯±å› 
    """
    def __init__(self, in_channels, hidden_dim=256, out_channels=None, 
                 expert_type="general", dropout=0.1):
        super().__init__()
        
        self.expert_type = expert_type
        out_channels = out_channels or in_channels
        
        # ä¸“å®¶ç‰¹å®šçš„ç‰¹å¾æå–
        self.feature_extraction = nn.Sequential(
            nn.Conv2d(in_channels, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout2d(dropout),
            
            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout2d(dropout)
        )
        
        # ä¸“å®¶ç‰¹å®šçš„æ³¨æ„åŠ›æœºåˆ¶
        self.expert_attention = nn.Sequential(
            nn.Conv2d(hidden_dim, hidden_dim // 4, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 4, 1, 1),
            nn.Sigmoid()
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_projection = nn.Sequential(
            nn.Conv2d(hidden_dim, out_channels, 1),
            nn.BatchNorm2d(out_channels)
        )
        
        # ä¸“å®¶ç±»å‹åµŒå…¥ï¼ˆç”¨äºæ¡ä»¶åŒ–å¤„ç†ï¼‰
        self.type_embedding = nn.Parameter(torch.randn(1, hidden_dim, 1, 1))
        
    def forward(self, x, confidence=1.0):
        """
        Args:
            x: [B, C, H, W] - è¾“å…¥ç‰¹å¾
            confidence: æ ‡é‡ - è¯¥ä¸“å®¶çš„ç½®ä¿¡åº¦
        """
        # ç‰¹å¾æå–
        features = self.feature_extraction(x)
        
        # æ·»åŠ ä¸“å®¶ç±»å‹åµŒå…¥
        features = features + self.type_embedding
        
        # ç”Ÿæˆä¸“å®¶ç‰¹å®šçš„æ³¨æ„åŠ›
        attention = self.expert_attention(features)
        
        # åº”ç”¨æ³¨æ„åŠ›
        attended_features = features * attention
        
        # è¾“å‡ºæŠ•å½±
        output = self.output_projection(attended_features)
        
        # åº”ç”¨ç½®ä¿¡åº¦åŠ æƒ
        output = output * confidence
        
        # æ®‹å·®è¿æ¥
        if output.shape == x.shape:
            output = output + x
        
        return output, attention


class GatingNetwork(nn.Module):
    """
    é—¨æ§ç½‘ç»œï¼ˆè·¯ç”±å™¨ï¼‰
    æ ¹æ®è¾“å…¥ç‰¹å¾å’Œæ¡ä»¶ä¿¡æ¯å†³å®šæ¯ä¸ªä¸“å®¶çš„æƒé‡
    """
    def __init__(self, in_channels, num_experts, num_conditions=5, 
                 temperature=1.0, use_load_balancing=True):
        super().__init__()
        
        self.num_experts = num_experts
        self.num_conditions = num_conditions
        self.temperature = temperature
        self.use_load_balancing = use_load_balancing
        
        # ç‰¹å¾ç¼–ç å™¨
        self.feature_encoder = nn.Sequential(
            nn.Conv2d(in_channels, 128, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten()
        )
        
        # æ¡ä»¶åµŒå…¥
        self.condition_embedding = nn.Embedding(num_conditions, 64)
        
        # é—¨æ§å†³ç­–ç½‘ç»œ
        self.gate_network = nn.Sequential(
            nn.Linear(128 + 64, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(256, num_experts)
        )
        
        # è´Ÿè½½å‡è¡¡æŸå¤±çš„é‡è¦æ€§å› å­
        if use_load_balancing:
            self.importance_network = nn.Linear(128, num_experts)
            
    def forward(self, x, condition_id=None):
        """
        Args:
            x: [B, C, H, W] - è¾“å…¥ç‰¹å¾
            condition_id: [B] - æ¡ä»¶IDï¼ˆæ»‘å¡è¯±å› ç±»åˆ«ï¼‰
        
        Returns:
            gates: [B, num_experts] - æ¯ä¸ªä¸“å®¶çš„æƒé‡
            load_balance_loss: è´Ÿè½½å‡è¡¡æŸå¤±
        """
        B = x.shape[0]
        
        # ç¼–ç ç‰¹å¾
        feat_encoding = self.feature_encoder(x)  # [B, 128]
        
        # å¤„ç†æ¡ä»¶ä¿¡æ¯
        if condition_id is not None:
            condition_emb = self.condition_embedding(condition_id)  # [B, 64]
            combined = torch.cat([feat_encoding, condition_emb], dim=1)
        else:
            # å¦‚æœæ²¡æœ‰æ¡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤åµŒå…¥
            default_cond = torch.zeros(B, 64, device=x.device)
            combined = torch.cat([feat_encoding, default_cond], dim=1)
        
        # è®¡ç®—é—¨æ§æƒé‡
        logits = self.gate_network(combined)  # [B, num_experts]
        
        # åº”ç”¨æ¸©åº¦å’Œsoftmax
        gates = F.softmax(logits / self.temperature, dim=1)
        
        # è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±
        load_balance_loss = 0.0
        if self.use_load_balancing and self.training:
            # è®¡ç®—é‡è¦æ€§åˆ†æ•°
            importance = self.importance_network(feat_encoding)
            importance = F.softmax(importance, dim=1)
            
            # è´Ÿè½½å‡è¡¡æŸå¤±ï¼šé¼“åŠ±å‡åŒ€ä½¿ç”¨ä¸“å®¶
            load = gates.mean(dim=0)  # æ¯ä¸ªä¸“å®¶çš„å¹³å‡è´Ÿè½½
            load_balance_loss = self.num_experts * (load * load).sum()
            
        return gates, load_balance_loss


class ConditionalMoE(nn.Module):
    """
    æ¡ä»¶åŒ–ä¸“å®¶æ··åˆå±‚
    æ ¹æ®æ»‘å¡è¯±å› åŠ¨æ€é€‰æ‹©å’Œç»„åˆå¤šä¸ªä¸“å®¶çš„é¢„æµ‹
    """
    def __init__(self, in_channels, num_experts=4, num_conditions=5,
                 expert_types=None, hidden_dim=256, temperature=1.0,
                 use_load_balancing=True, dropout=0.1):
        super().__init__()
        
        self.in_channels = in_channels
        self.num_experts = num_experts
        self.num_conditions = num_conditions
        
        # å®šä¹‰ä¸“å®¶ç±»å‹
        if expert_types is None:
            expert_types = ["rainfall", "earthquake", "human", "complex"]
        
        # åˆ›å»ºä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList()
        for i in range(num_experts):
            expert_type = expert_types[i] if i < len(expert_types) else "general"
            self.experts.append(
                ExpertNetwork(
                    in_channels, hidden_dim, in_channels,
                    expert_type=expert_type, dropout=dropout
                )
            )
        
        # åˆ›å»ºé—¨æ§ç½‘ç»œ
        self.gating = GatingNetwork(
            in_channels, num_experts, num_conditions,
            temperature=temperature, use_load_balancing=use_load_balancing
        )
        
        # Top-ké€‰æ‹©ï¼ˆå¯é€‰ï¼‰
        self.top_k = min(2, num_experts)  # åªæ¿€æ´»top-kä¸ªä¸“å®¶
        
        print(f"ğŸ¯ åˆå§‹åŒ–æ¡ä»¶åŒ–MoEå±‚:")
        print(f"   ä¸“å®¶æ•°é‡: {num_experts}")
        print(f"   ä¸“å®¶ç±»å‹: {expert_types[:num_experts]}")
        print(f"   æ¡ä»¶ç±»åˆ«æ•°: {num_conditions}")
        print(f"   Top-ké€‰æ‹©: {self.top_k}")
        
    def forward(self, x, condition_id=None, return_expert_outputs=False):
        """
        Args:
            x: [B, C, H, W] - è¾“å…¥çš„å˜åŒ–ç‰¹å¾ï¼ˆæ¥è‡ªç¬¬å››é˜¶æ®µï¼‰
            condition_id: [B] - æ»‘å¡è¯±å› ç±»åˆ«ID
            return_expert_outputs: æ˜¯å¦è¿”å›å„ä¸“å®¶çš„å•ç‹¬è¾“å‡ºï¼ˆç”¨äºåˆ†æï¼‰
        
        Returns:
            output: [B, C, H, W] - æœ€ç»ˆçš„å˜åŒ–ç‰¹å¾
            aux_loss: è¾…åŠ©æŸå¤±ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
        """
        B, C, H, W = x.shape
        
        # è·å–é—¨æ§æƒé‡
        gates, load_balance_loss = self.gating(x, condition_id)  # [B, num_experts]
        
        # Top-ké€‰æ‹©
        if self.top_k < self.num_experts:
            topk_gates, topk_indices = torch.topk(gates, self.top_k, dim=1)
            # å½’ä¸€åŒ–top-kæƒé‡
            topk_gates = topk_gates / topk_gates.sum(dim=1, keepdim=True)
        else:
            topk_gates = gates
            topk_indices = torch.arange(self.num_experts).expand(B, -1).to(x.device)
        
        # æ”¶é›†ä¸“å®¶è¾“å‡º
        expert_outputs = []
        expert_attentions = []
        
        for i in range(self.num_experts):
            # åˆ›å»ºä¸“å®¶æ©ç 
            expert_mask = (topk_indices == i).any(dim=1)
            
            if expert_mask.any():
                # è·å–è¯¥ä¸“å®¶çš„ç½®ä¿¡åº¦
                confidence = gates[:, i].view(B, 1, 1, 1)
                
                # è¿è¡Œä¸“å®¶ç½‘ç»œ
                expert_out, expert_attn = self.experts[i](x, confidence)
                expert_outputs.append(expert_out)
                expert_attentions.append(expert_attn)
            else:
                # å¦‚æœè¯¥ä¸“å®¶æœªè¢«é€‰ä¸­ï¼Œå¡«å……é›¶
                expert_outputs.append(torch.zeros_like(x))
                expert_attentions.append(torch.zeros(B, 1, H, W, device=x.device))
        
        # ç»„åˆä¸“å®¶è¾“å‡º
        if self.top_k < self.num_experts:
            # åªç»„åˆtop-kä¸“å®¶
            output = torch.zeros_like(x)
            for b in range(B):
                for k in range(self.top_k):
                    expert_idx = topk_indices[b, k]
                    weight = topk_gates[b, k]
                    output[b] += weight * expert_outputs[expert_idx][b]
        else:
            # ç»„åˆæ‰€æœ‰ä¸“å®¶
            expert_outputs_stack = torch.stack(expert_outputs, dim=1)  # [B, num_experts, C, H, W]
            gates_expanded = gates.view(B, self.num_experts, 1, 1, 1)
            output = (expert_outputs_stack * gates_expanded).sum(dim=1)
        
        # å‡†å¤‡è¿”å›å€¼
        if return_expert_outputs:
            return output, load_balance_loss, {
                'expert_outputs': expert_outputs,
                'expert_attentions': expert_attentions,
                'gates': gates,
                'topk_indices': topk_indices if self.top_k < self.num_experts else None
            }
        
        return output, load_balance_loss


class MultiScaleMoE(nn.Module):
    """
    å¤šå°ºåº¦MoEå±‚
    ä¸ºä¸åŒå°ºåº¦é…ç½®ä¸åŒçš„ä¸“å®¶ç»„åˆ
    """
    def __init__(self, scale_dims, num_experts=4, num_conditions=5,
                 scale_specific_experts=None, temperature=1.0,
                 use_load_balancing=True, dropout=0.1):
        super().__init__()
        
        self.scale_dims = scale_dims
        self.moe_layers = nn.ModuleList()
        
        # ä¸ºæ¯ä¸ªå°ºåº¦åˆ›å»ºMoEå±‚
        for i, dim in enumerate(scale_dims):
            # å¯ä»¥ä¸ºä¸åŒå°ºåº¦é…ç½®ä¸åŒçš„ä¸“å®¶ç±»å‹
            if scale_specific_experts and i < len(scale_specific_experts):
                expert_types = scale_specific_experts[i]
            else:
                # é»˜è®¤ä¸“å®¶ç±»å‹
                expert_types = ["rainfall", "earthquake", "human", "complex"]
            
            moe = ConditionalMoE(
                dim, num_experts, num_conditions,
                expert_types=expert_types,
                hidden_dim=min(256, dim * 2),  # æ ¹æ®é€šé“æ•°è°ƒæ•´éšè—ç»´åº¦
                temperature=temperature,
                use_load_balancing=use_load_balancing,
                dropout=dropout
            )
            
            self.moe_layers.append(moe)
    
    def forward(self, x, condition_id, scale_idx):
        """
        æ ¹æ®å°ºåº¦é€‰æ‹©å¯¹åº”çš„MoEå±‚
        
        Args:
            x: [B, C, H, W] - è¾“å…¥ç‰¹å¾
            condition_id: [B] - æ¡ä»¶ID
            scale_idx: å½“å‰å°ºåº¦ç´¢å¼•
        """
        if scale_idx < len(self.moe_layers):
            return self.moe_layers[scale_idx](x, condition_id)
        else:
            # è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨æœ€åä¸€ä¸ª
            return self.moe_layers[-1](x, condition_id)


# å®šä¹‰æ»‘å¡è¯±å› ç±»åˆ«
LANDSLIDE_TRIGGERS = {
    0: "rainfall",      # é™é›¨å¼•å‘
    1: "earthquake",    # åœ°éœ‡å¼•å‘  
    2: "human",         # äººç±»æ´»åŠ¨å¼•å‘
    3: "snowmelt",      # èé›ªå¼•å‘
    4: "complex"        # å¤åˆå› ç´ 
}


def create_condition_embedding(batch_size, trigger_type, device):
    """
    åˆ›å»ºæ¡ä»¶åµŒå…¥çš„è¾…åŠ©å‡½æ•°
    
    Args:
        batch_size: æ‰¹æ¬¡å¤§å°
        trigger_type: è§¦å‘ç±»å‹ï¼ˆintæˆ–strï¼‰
        device: è®¾å¤‡
    """
    if isinstance(trigger_type, str):
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºID
        trigger_id = [k for k, v in LANDSLIDE_TRIGGERS.items() if v == trigger_type][0]
    else:
        trigger_id = trigger_type
    
    condition_ids = torch.full((batch_size,), trigger_id, dtype=torch.long, device=device)
    return condition_ids