import os
import time
import argparse
import json
import warnings
import torch
import torch.nn as nn
import contextlib
import gc
import sys
import inspect
from collections import OrderedDict

# å¿…è¦çš„å¯¼å…¥
import utils
import Data
import Model
from tensorboardX import SummaryWriter
from torch.utils.data import DataLoader

# è®¾ç½®è­¦å‘Šå’Œå¼‚å¸¸å¤„ç†
warnings.filterwarnings("ignore")
torch.autograd.set_detect_anomaly(True)

# ==================== å†…å­˜ç®¡ç†å·¥å…· ====================
@contextlib.contextmanager
def memory_efficient_context():
    """å†…å­˜é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    try:
        yield
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

# ==================== æ ‡ç­¾éªŒè¯å™¨ ====================
class LabelValidator:
    """ç»Ÿä¸€çš„æ ‡ç­¾éªŒè¯å’Œé€‚é…å™¨"""
    def __init__(self):
        self.logged_info = set()
    
    def validate_and_fix_labels(self, data, phase="train"):
        """éªŒè¯å¹¶ä¿®å¤æ ‡ç­¾æ ¼å¼"""
        if 'L' not in data:
            return
        
        label = data['L']
        original_shape = label.shape
        original_dtype = label.dtype
        unique_before = torch.unique(label)
        
        # ç¡®ä¿æ ‡ç­¾æ˜¯æ­£ç¡®çš„å½¢çŠ¶
        if len(label.shape) == 4 and label.shape[1] == 1:
            label = label.squeeze(1)
            data['L'] = label
        
        # ç¡®ä¿æ ‡ç­¾æ˜¯longç±»å‹
        if label.dtype != torch.long:
            data['L'] = label.long()
        
        # è®°å½•éªŒè¯ä¿¡æ¯ï¼ˆåªè®°å½•ä¸€æ¬¡ï¼‰
        info_key = f"{phase}_label_validation"
        if info_key not in self.logged_info:
            unique_after = torch.unique(data['L'])
            print(f"ğŸ“Š æ ‡ç­¾éªŒè¯ ({phase}):")
            print(f"   åŸå§‹å½¢çŠ¶: {original_shape} -> {data['L'].shape}")
            print(f"   æ•°æ®ç±»å‹: {original_dtype} -> {data['L'].dtype}")
            print(f"   å”¯ä¸€å€¼: {unique_before.tolist()} -> {unique_after.tolist()}")
            self.logged_info.add(info_key)
    
    def validate_physical_data(self, data, phase="train"):
        """éªŒè¯ç‰©ç†æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        if 'physical_data' not in data:
            return
        
        info_key = f"{phase}_physical_validation"
        if info_key not in self.logged_info:
            phys_data = data['physical_data']
            print(f"ğŸŒ¡ï¸ ç‰©ç†æ•°æ®éªŒè¯ ({phase}):")
            print(f"   å½¢çŠ¶: {phys_data.shape}")
            print(f"   æ•°æ®ç±»å‹: {phys_data.dtype}")
            print(f"   èŒƒå›´: [{phys_data.min():.3f}, {phys_data.max():.3f}]")
            self.logged_info.add(info_key)

# åˆ›å»ºå…¨å±€éªŒè¯å™¨å®ä¾‹
label_validator = LabelValidator()

# ==================== æ€§èƒ½ç›‘æ§ ====================
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    def __init__(self):
        self.step_times = []
        self.gpu_memory_usage = []
        self.last_report_step = 0
    
    def record_step(self, step_time):
        self.step_times.append(step_time)
        if torch.cuda.is_available():
            self.gpu_memory_usage.append(torch.cuda.memory_allocated() / 1024**3)
    
    def report(self, current_step, interval=100):
        if current_step - self.last_report_step >= interval and len(self.step_times) > 0:
            avg_time = sum(self.step_times[-interval:]) / len(self.step_times[-interval:])
            if self.gpu_memory_usage:
                avg_memory = sum(self.gpu_memory_usage[-interval:]) / len(self.gpu_memory_usage[-interval:])
                print(f"âš¡ æ€§èƒ½ç»Ÿè®¡: å¹³å‡æ­¥éª¤æ—¶é—´={avg_time:.3f}s, GPUå†…å­˜={avg_memory:.2f}GB")
            else:
                print(f"âš¡ æ€§èƒ½ç»Ÿè®¡: å¹³å‡æ­¥éª¤æ—¶é—´={avg_time:.3f}s")
            self.last_report_step = current_step

# ==================== æ¨¡å‹å…¼å®¹æ€§ç¡®ä¿ ====================
def ensure_cd_model_compatibility(cd_model, opt):
    """ç¡®ä¿CDæ¨¡å‹å…·æœ‰æ‰€éœ€çš„æ–¹æ³•å’Œå±æ€§"""
    # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„æ–¹æ³•
    if not hasattr(cd_model, '_collect_running_batch_states'):
        def _collect_running_batch_states(self):
            self.running_acc = self._update_metric()
            
            m = len(self.log_dict) 
            if m == self.len_train_dataloader:
                for key in self.log_dict.keys():
                    self.log_dict[key] /= m
                    
                message = '[Training CD]. epoch: [%d/%d]. Aver_running_acc:%.5f\n' % \
                        (self.epoch, self.opt['n_epoch']-1, self.running_acc/m)
                for k, v in self.log_dict.items():
                    message += '%s: %.4e ' % (k, v)
                    self.tb_logger.add_scalar(k, v, self.global_step)
                    
                self.logger.info(message)
                self.log_dict = OrderedDict()
        
        cd_model._collect_running_batch_states = lambda: _collect_running_batch_states(cd_model)
    
    if not hasattr(cd_model, '_clear_cache'):
        def _clear_cache(self):
            self.running_metric.clear()
        
        cd_model._clear_cache = lambda: _clear_cache(cd_model)
    
    if not hasattr(cd_model, '_update_metric'):
        def _update_metric(self):
            if hasattr(self, 'change_prediction') and hasattr(self, 'label'):
                G_pred = self.change_prediction.detach()
                G_pred = torch.argmax(G_pred, dim=1)
                current_score = self.running_metric.update_cm(
                    pr=G_pred.cpu().numpy(), 
                    gt=self.label.detach().cpu().numpy()
                )
                return current_score
            return 0.0
        
        cd_model._update_metric = lambda: _update_metric(cd_model)
    
    return cd_model

# ==================== ç‰¹å¾å¤„ç†å’ŒCDæ¨¡å‹è°ƒç”¨ ====================
def process_features_for_cd(change_detection, features_A, features_B, data, current_epoch=None, phase='train'):
    """
    ç»Ÿä¸€å¤„ç†ç‰¹å¾å¹¶è°ƒç”¨CDæ¨¡å‹çš„ç›¸åº”æ–¹æ³•
    """
    try:
        # æ£€æŸ¥æ¨¡å‹æ¥å£ç‰ˆæœ¬
        feed_data_params = inspect.signature(change_detection.feed_data).parameters
        
        if len(feed_data_params) == 2:  # æ–°æ¥å£: feed_data(self, data)
            change_detection.feed_data(data)
            
            if phase == 'train':
                # æ£€æŸ¥optimize_parametersçš„å‚æ•°
                if hasattr(change_detection.optimize_parameters, '__code__'):
                    opt_params = change_detection.optimize_parameters.__code__.co_varnames
                    if 'features_A' in opt_params:
                        change_detection.optimize_parameters(features_A, features_B, current_epoch=current_epoch)
                    else:
                        # é€šè¿‡ä¸´æ—¶å±æ€§ä¼ é€’ç‰¹å¾
                        change_detection._temp_features_A = features_A
                        change_detection._temp_features_B = features_B
                        change_detection.optimize_parameters()
                else:
                    change_detection._temp_features_A = features_A
                    change_detection._temp_features_B = features_B
                    change_detection.optimize_parameters()
            else:
                # éªŒè¯/æµ‹è¯•é˜¶æ®µ
                if hasattr(change_detection, 'test'):
                    test_params = inspect.signature(change_detection.test).parameters if hasattr(change_detection.test, '__call__') else []
                    if len(test_params) > 1:
                        change_detection.test(features_A, features_B)
                    else:
                        change_detection._temp_features_A = features_A
                        change_detection._temp_features_B = features_B
                        change_detection.test()
        
        else:  # æ—§æ¥å£: feed_data(self, features_A, features_B, data)
            change_detection.feed_data(features_A, features_B, data)
            if phase == 'train':
                change_detection.optimize_parameters()
            else:
                change_detection.test()
        
        # æ¸…ç†ä¸´æ—¶ç‰¹å¾
        if hasattr(change_detection, '_temp_features_A'):
            del change_detection._temp_features_A
        if hasattr(change_detection, '_temp_features_B'):
            del change_detection._temp_features_B
            
    except Exception as e:
        print(f"âŒ ç‰¹å¾å¤„ç†é”™è¯¯ ({phase}): {e}")
        import traceback
        traceback.print_exc()
        raise

# ==================== é«˜æ•ˆæ‰¹é‡å¤„ç† ====================
def process_batch_efficiently(train_data, diffusion, change_detection, opt, phase="train", current_epoch=None):
    """é«˜æ•ˆçš„æ‰¹é‡å¤„ç† - æ”¯æŒcd_head_v8çš„ç›´æ¥è°ƒç”¨"""
    with memory_efficient_context():
        try:
            # 1. æ ‡ç­¾éªŒè¯
            label_validator.validate_and_fix_labels(train_data, phase)
            
            # 2. ç‰©ç†æ•°æ®éªŒè¯å’Œå‡†å¤‡
            physical_data = None
            if opt['model_cd'].get('physics_attention', {}).get('enabled', False):
                if 'physical_data' in train_data:
                    physical_data = train_data['physical_data']
                    label_validator.validate_physical_data(train_data, phase)
                else:
                    print("âš ï¸ ç‰©ç†æ³¨æ„åŠ›å·²å¯ç”¨ä½†æœªæ‰¾åˆ°ç‰©ç†æ•°æ®")
            
            # 3. è®¾å¤‡ä¸€è‡´æ€§
            device = next(diffusion.netG.parameters()).device
            for key, value in train_data.items():
                if torch.is_tensor(value):
                    train_data[key] = value.to(device)
            
            # 4. Diffusionç‰¹å¾æå–
            diffusion.feed_data(train_data)
            
            # 5. æ”¶é›†å¤šæ—¶é—´æ­¥ç‰¹å¾
            f_A, f_B = [], []
            for t in opt['model_cd']['t']:
                fe_A_t, fd_A_t, fe_B_t, fd_B_t = diffusion.get_feats(t=t)
                if opt['model_cd']['feat_type'] == "dec":
                    f_A.append(fd_A_t)
                    f_B.append(fd_B_t)
                    del fe_A_t, fe_B_t
                else:
                    f_A.append(fe_A_t)
                    f_B.append(fe_B_t)
                    del fd_A_t, fd_B_t
            
            # 6. ç‰¹å¾é‡æ’ï¼ˆä¸ºcd_head_v8å‡†å¤‡æ­£ç¡®æ ¼å¼ï¼‰
            feat_scales = opt['model_cd']['feat_scales']
            cd_expected_order = sorted(feat_scales, reverse=True)
            
            reordered_f_A = []
            reordered_f_B = []
            
            for fa, fb in zip(f_A, f_B):
                if isinstance(fa, list) and len(fa) > max(feat_scales):
                    timestep_A = [fa[scale] for scale in cd_expected_order]
                    timestep_B = [fb[scale] for scale in cd_expected_order]
                    reordered_f_A.append(timestep_A)
                    reordered_f_B.append(timestep_B)
            
            # 7. æ£€æŸ¥cd_head_v8çš„forwardæ–¹æ³•å¹¶ç›´æ¥è°ƒç”¨
            if hasattr(change_detection.netCD, 'forward') and opt['model_cd'].get('version') == 'v8':
                # cd_head_v8å¯ä»¥ç›´æ¥è°ƒç”¨forward
                change_detection.feed_data(train_data)
                
                if phase == 'train':
                    # è®­ç»ƒæ—¶è°ƒç”¨netCD.forwardå¹¶è®¡ç®—æŸå¤±
                    cm = change_detection.netCD(reordered_f_A, reordered_f_B, physical_data)
                    change_detection.change_prediction = cm
                    
                    # è®¡ç®—æŸå¤±å’Œä¼˜åŒ–
                    change_detection.cal_loss()
                    change_detection.optCD.zero_grad()
                    change_detection.loss_v.backward()
                    change_detection.optCD.step()
                    
                    # æ›´æ–°æŒ‡æ ‡
                    change_detection._update_metric()
                else:
                    # æµ‹è¯•/éªŒè¯é˜¶æ®µ
                    with torch.no_grad():
                        cm = change_detection.netCD(reordered_f_A, reordered_f_B, physical_data)
                        change_detection.change_prediction = cm
                        change_detection._update_metric()
                        
            else:
                # æ—§ç‰ˆæœ¬æ¨¡å‹çš„å¤„ç†
                process_features_for_cd(change_detection, reordered_f_A, reordered_f_B, 
                                      train_data, current_epoch, phase)
            
            # 8. æ¸…ç†å†…å­˜
            del f_A, f_B, reordered_f_A, reordered_f_B
            
        except Exception as e:
            print(f"âŒ æ‰¹å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            raise

# ==================== è®­ç»ƒä¼˜åŒ–è®¾ç½® ====================
def setup_training_optimization(diffusion, change_detection):
    """è®¾ç½®è®­ç»ƒä¼˜åŒ–"""
    print("ğŸš€ è®¾ç½®è®­ç»ƒä¼˜åŒ–...")
    
    # å¯ç”¨CUDAä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    
    # æ£€æŸ¥æ··åˆç²¾åº¦æ”¯æŒ
    use_amp = False
    if torch.cuda.is_available():
        try:
            from torch.cuda.amp import autocast, GradScaler
            use_amp = True
            print("   âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ")
        except ImportError:
            print("   âš ï¸  ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ")
    
    # è®¾ç½®diffusionæ¨¡å‹ä¸ºevalæ¨¡å¼
    if hasattr(diffusion.netG, 'eval'):
        diffusion.netG.eval()
        print("   âœ… Diffusionæ¨¡å‹è®¾ç½®ä¸ºevalæ¨¡å¼")
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    if torch.cuda.device_count() > 1:
        print(f"   âœ… æ£€æµ‹åˆ°{torch.cuda.device_count()}ä¸ªGPU")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / 1024**3
            print(f"     GPU {i}: {props.name} ({memory_gb:.1f}GB)")
    
    print("ğŸš€ è®­ç»ƒä¼˜åŒ–è®¾ç½®å®Œæˆ\n")
    
    return use_amp

# ==================== éªŒè¯å’Œæµ‹è¯•åŠŸèƒ½ ====================
def validation(val_loader, epoch, diffusion, change_detection, opt, tb_logger):
    """æ‰§è¡ŒéªŒè¯"""
    avg_loss = 0.0
    diffusion.eval()
    change_detection._clear_cache()
    
    with torch.no_grad():
        for _, val_data in enumerate(val_loader):
            process_batch_efficiently(val_data, diffusion, change_detection, opt, phase="val")
            avg_loss += change_detection.loss_v
    
    avg_loss = avg_loss / len(val_loader)
    
    # è·å–æ€§èƒ½æŒ‡æ ‡
    scores_dict = change_detection.running_metric.get_cm()
    
    # ä½¿ç”¨æä¾›çš„è®¡ç®—å‡½æ•°
    val_metrics = compute_metrics(scores_dict)
    
    # è®°å½•åˆ°tensorboard
    tb_logger.add_scalar('[Val] Loss_epoch', avg_loss, epoch)
    print(f"\n[Val] epoch: {epoch}. loss: {avg_loss:.5f}. "
          f"F1: {val_metrics['mF1']:.5f}, IoU: {val_metrics['mIoU']:.5f}")
    
    return val_metrics

def compute_metrics(conf_mat_dict):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    tn = conf_mat_dict['tn']
    fp = conf_mat_dict['fp']
    fn = conf_mat_dict['fn'] 
    tp = conf_mat_dict['tp']
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0
    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1_0 = 2 * precision_0 * recall_0 / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0
    iou_0 = tn / (tn + fn + fp) if (tn + fn + fp) > 0 else 0
    
    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_1 = 2 * precision_1 * recall_1 / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0
    iou_1 = tp / (tp + fn + fp) if (tp + fn + fp) > 0 else 0
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    mf1 = (f1_0 + f1_1) / 2
    miou = (iou_0 + iou_1) / 2
    
    return {
        'mF1': mf1,
        'mIoU': miou,
        'F1_change': f1_1,
        'IoU_change': iou_1,
        'Precision_change': precision_1,
        'Recall_change': recall_1,
        'F1_no_change': f1_0,
        'IoU_no_change': iou_0,
        'Precision_no_change': precision_0,
        'Recall_no_change': recall_0,
    }

# ==================== ä¸»å‡½æ•° ====================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('-c', '--config', type=str, default='config/ddpm_cd.json',
                        help='JSON file for configuration')
    parser.add_argument('-p', '--phase', type=str, choices=['train', 'test'],
                        help='Run either train(training + validation) or testing', default='train')
    parser.add_argument('-gpu', '--gpu_ids', type=str, default=None)
    parser.add_argument('-debug', '-d', action='store_true')
    parser.add_argument('-enable_wandb', action='store_true')
    parser.add_argument('-log_eval', action='store_true')
    
    # ç‰©ç†æŸå¤±ç›¸å…³å‚æ•°
    parser.add_argument('--use_physics_loss', action='store_true',
                        help='Enable physics-constrained loss')
    parser.add_argument('--physics_config', type=str, default=None,
                        help='Override physics loss config file')

    # è§£æå‚æ•°
    args = parser.parse_args()
    opt = utils.parse(args)
    opt = utils.dict_to_nonedict(opt)

    # è®¾ç½®æ—¥å¿—
    utils.mkdirs(
        (path for key, path in opt['path'].items() if not key == 'experiments_root'))
    utils.setup_logger(None, opt['path']['log'], 'train', level=logging.INFO, screen=True)
    utils.setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)
    logger = logging.getLogger('base')
    logger.info(utils.dict2str(opt))
    tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(12345)
    
    # ==================== æ•°æ®é›†å‡†å¤‡ ====================
    print("\n" + "="*50)
    print("ğŸ”§ å‡†å¤‡æ•°æ®é›†...")
    print("="*50)
    
    for phase, dataset in opt['datasets'].items():
        if phase == 'train' and args.phase == 'train':
            print("Creating [train] change-detection dataloader.")
            dataset_opt = dataset
            train_set = Data.create_cd_dataset(dataset_opt, phase)
            train_loader = Data.create_cd_dataloader(train_set, dataset_opt, phase)
            opt['len_train_dataloader'] = len(train_loader)
            
        elif phase == 'val' and args.phase == 'train':
            print("Creating [val] change-detection dataloader.")
            dataset_opt = dataset
            val_set = Data.create_cd_dataset(dataset_opt, phase)
            val_loader = Data.create_cd_dataloader(val_set, dataset_opt, phase)
            opt['len_val_dataloader'] = len(val_loader)
        
        elif phase == 'test' and args.phase == 'test':
            print("Creating [test] change-detection dataloader.")
            test_set = Data.create_cd_dataset(dataset_opt, phase)
            test_loader = Data.create_cd_dataloader(test_set, dataset_opt, phase)
            opt['len_test_dataloader'] = len(test_loader)
    
    logger.info('Initial Dataset Finished')

    # ==================== æ¨¡å‹åŠ è½½ ====================
    print("ğŸ”„ åŠ è½½æ‰©æ•£æ¨¡å‹...")
    diffusion = Model.create_model(opt)
    logger.info('Initial Diffusion Model Finished')

    # å¤„ç†DataParallel
    if isinstance(diffusion.netG, nn.DataParallel):
        diffusion.netG = diffusion.netG.module
        print("å·²è§£åŒ…diffusionæ¨¡å‹çš„DataParallel")

    # å¤šGPUè®¾ç½®
    if torch.cuda.device_count() > 1:
        print(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œè®­ç»ƒ")
        diffusion.netG = diffusion.netG.cuda()
        diffusion.netG = nn.DataParallel(diffusion.netG)

    # è®¾ç½®å™ªå£°è°ƒåº¦
    diffusion.set_new_noise_schedule(
        opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])
    
    # åˆ›å»ºå˜åŒ–æ£€æµ‹æ¨¡å‹
    print("ğŸ”„ åŠ è½½å˜åŒ–æ£€æµ‹æ¨¡å‹...")
    try:
        change_detection = Model.create_CD_model(opt)
        
        # ç¡®ä¿å…¼å®¹æ€§
        change_detection = ensure_cd_model_compatibility(change_detection, opt)
        
        print(f"âœ… æˆåŠŸåˆ›å»ºCDæ¨¡å‹: {change_detection.__class__.__name__}")
        
        # ç‰¹åˆ«å¤„ç†cd_head_v8
        if opt['model_cd'].get('version') == 'v8':
            print("ğŸ”§ æ£€æµ‹åˆ°cd_head_v8æ¨¡å‹")
            
            # æ£€æŸ¥å„ä¸ªæ¨¡å—çš„å¯ç”¨çŠ¶æ€
            if hasattr(change_detection, 'netCD'):
                netCD = change_detection.netCD
                print(f"   ç‰©ç†æ³¨æ„åŠ›: {'âœ“' if netCD.use_physics else 'âœ—'}")
                print(f"   äº¤å‰æ³¨æ„åŠ›: {'âœ“' if netCD.use_cross_attention else 'âœ—'}")
                print(f"   Mambaå…¨å±€åˆ†æ: {'âœ“' if netCD.use_mamba else 'âœ—'}")
                print(f"   ç‰©ç†èšç„¦: {'âœ“' if netCD.use_physics_focus else 'âœ—'}")
                print(f"   MoEä¸“å®¶å†³ç­–: {'âœ“' if netCD.use_moe else 'âœ—'}")
        
        # æ£€æŸ¥ç‰©ç†æŸå¤±æ”¯æŒ
        if opt['model_cd'].get('loss_type') == 'physics_constrained':
            if hasattr(change_detection, 'criterion'):
                print(f"âœ… ç‰©ç†æŸå¤±å‡½æ•°å·²é…ç½®: {change_detection.criterion.__class__.__name__}")
            else:
                print("âš ï¸  è­¦å‘Šï¼šæ¨¡å‹å¯èƒ½ä¸æ”¯æŒç‰©ç†æŸå¤±")
        
    except Exception as e:
        print(f"âŒ CDæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if not hasattr(change_detection, 'running_metric'):
        print("ğŸ”§ ä¸ºCDæ¨¡å‹æ·»åŠ æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨...")
        from misc.metric_tools import ConfuseMatrixMeter
        change_detection.running_metric = ConfuseMatrixMeter(n_class=opt['model_cd']['out_channels'])

    # è®¾ç½®æ•°æ®é›†é•¿åº¦ä¿¡æ¯
    if 'len_train_dataloader' in opt:
        change_detection.len_train_dataloader = opt["len_train_dataloader"]
    if 'len_val_dataloader' in opt:
        change_detection.len_val_dataloader = opt["len_val_dataloader"]

    print("ğŸš€ å˜åŒ–æ£€æµ‹æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n")
    
    # è®¾å¤‡ä¸€è‡´æ€§è®¾ç½®
    if torch.cuda.is_available():
        target_device = torch.device('cuda:0')
        
        # ç¡®ä¿æ¨¡å‹åœ¨GPU
        if isinstance(diffusion.netG, nn.DataParallel):
            diffusion.netG.module = diffusion.netG.module.to(target_device)
        else:
            diffusion.netG = diffusion.netG.to(target_device)
        
        if hasattr(change_detection, 'netCD') and change_detection.netCD is not None:
            if isinstance(change_detection.netCD, nn.DataParallel):
                change_detection.netCD.module = change_detection.netCD.module.to(target_device)
            else:
                change_detection.netCD = change_detection.netCD.to(target_device)
        
        print(f"âœ… è®¾å¤‡è®¾ç½®å®Œæˆ: {target_device}")

    # è®¾ç½®è®­ç»ƒä¼˜åŒ–
    use_amp = setup_training_optimization(diffusion, change_detection)
    
    # åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
    performance_monitor = PerformanceMonitor()

    # ==================== è®­ç»ƒå¾ªç¯ ====================
    n_epoch = opt['train']['n_epoch']
    best_mF1 = 0.0
    start_epoch = 0

    if opt['phase'] == 'train':
        print("\n" + "="*50)
        print("ğŸš€ å¼€å§‹è®­ç»ƒ")
        print("="*50)
        
        for current_epoch in range(start_epoch, n_epoch):
            epoch_start_time = time.time()
            change_detection._clear_cache()
            
            train_result_path = f'{opt["path"]["results"]}/train/{current_epoch}'
            os.makedirs(train_result_path, exist_ok=True)
            
            # è®­ç»ƒé˜¶æ®µ
            print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ Epoch {current_epoch}/{n_epoch-1}")
            message = f'å­¦ä¹ ç‡: {change_detection.optCD.param_groups[0]["lr"]:.7f}'
            logger.info(message)
            
            # è®¾ç½®cd_head_v8çš„epochï¼ˆå¦‚æœæ”¯æŒæ¡ä»¶MoEï¼‰
            if hasattr(change_detection.netCD, 'set_condition') and opt['model_cd'].get('moe_config', {}).get('enabled', False):
                # æ ¹æ®epochè®¾ç½®ä¸åŒçš„æ¡ä»¶
                if current_epoch < 20:
                    condition = 'rainfall'  # æ—©æœŸå…³æ³¨é™é›¨
                elif current_epoch < 50:
                    condition = 'snowmelt'  # ä¸­æœŸå…³æ³¨èé›ª
                else:
                    condition = 'complex'   # åæœŸå…³æ³¨å¤æ‚æƒ…å†µ
                change_detection.netCD.set_condition(condition)
                print(f"   MoEæ¡ä»¶è®¾ç½®ä¸º: {condition}")
            
            for current_step, train_data in enumerate(train_loader):
                step_start_time = time.time()
                
                # è®°å½•batch sizeç”¨äºMoE
                if hasattr(change_detection.netCD, '_batch_size'):
                    change_detection.netCD._batch_size = train_data['A'].shape[0]
                
                # å¤„ç†æ‰¹æ¬¡
                process_batch_efficiently(train_data, diffusion, change_detection, 
                                       opt, phase="train", current_epoch=current_epoch)
                
                # å¤„ç†MoEè¾…åŠ©æŸå¤±ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if hasattr(change_detection.netCD, 'moe_aux_loss') and change_detection.netCD.training:
                    moe_loss = change_detection.netCD.moe_aux_loss
                    if moe_loss is not None and moe_loss.requires_grad:
                        moe_loss.backward(retain_graph=True)
                        if current_step % 100 == 0:
                            print(f"   MoEè¾…åŠ©æŸå¤±: {moe_loss.item():.4f}")
                
                # æ›´æ–°æŒ‡æ ‡
                change_detection._collect_running_batch_states()
                
                # è®°å½•æ€§èƒ½
                step_time = time.time() - step_start_time
                performance_monitor.record_step(step_time)
                
                # å®šæœŸæŠ¥å‘Šæ€§èƒ½
                if current_step % 100 == 0:
                    performance_monitor.report(current_step)
                    
                    # è·å–å¹¶ä¿å­˜æ³¨æ„åŠ›å›¾ï¼ˆç”¨äºåˆ†æï¼‰
                    if hasattr(change_detection.netCD, 'get_attention_maps'):
                        attention_maps = change_detection.netCD.get_attention_maps()
                        if attention_maps:
                            # è¿™é‡Œå¯ä»¥ä¿å­˜æˆ–å¯è§†åŒ–æ³¨æ„åŠ›å›¾
                            pass
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                if current_step % 500 == 0:
                    utils.save_model(change_detection, current_epoch, current_step, opt)
            
            # éªŒè¯é˜¶æ®µ
            if current_epoch % opt['val']['val_epoch'] == 0:
                print(f"\nğŸ“Š å¼€å§‹éªŒè¯ Epoch {current_epoch}")
                val_metrics = validation(val_loader, current_epoch, diffusion, 
                                       change_detection, opt, tb_logger)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_metrics['mF1'] > best_mF1:
                    best_mF1 = val_metrics['mF1']
                    print(f"ğŸ† æ–°çš„æœ€ä½³mF1: {best_mF1:.5f}")
                    utils.save_best_model(change_detection, opt)
            
            # æ›´æ–°å­¦ä¹ ç‡
            change_detection.scheduler.step()
            
            # è®°å½•epochæ—¶é—´
            epoch_time = time.time() - epoch_start_time
            print(f"â±ï¸ Epoch {current_epoch} å®Œæˆï¼Œç”¨æ—¶: {epoch_time/60:.2f}åˆ†é’Ÿ")
            
    elif opt['phase'] == 'test':
        print("\n" + "="*50)
        print("ğŸ§ª å¼€å§‹æµ‹è¯•")
        print("="*50)
        
        change_detection._clear_cache()
        test_result_path = f'{opt["path"]["results"]}/test'
        os.makedirs(test_result_path, exist_ok=True)
        
        with torch.no_grad():
            for current_step, test_data in enumerate(test_loader):
                process_batch_efficiently(test_data, diffusion, change_detection, 
                                       opt, phase="test")
                
                # ä¿å­˜é¢„æµ‹ç»“æœ
                visuals = change_detection.get_current_visuals()
                img_name = os.path.splitext(os.path.basename(test_data['ID'][0]))[0]
                utils.save_images(visuals, test_result_path, img_name)
                
                if current_step % 50 == 0:
                    print(f"å¤„ç†è¿›åº¦: {current_step}/{len(test_loader)}")
        
        # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
        scores_dict = change_detection.running_metric.get_cm()
        test_metrics = compute_metrics(scores_dict)
        
        print("\nğŸ“Š æµ‹è¯•ç»“æœ:")
        for metric, value in test_metrics.items():
            print(f"   {metric}: {value:.5f}")
    
    print("\nâœ… ç¨‹åºæ‰§è¡Œå®Œæˆï¼")